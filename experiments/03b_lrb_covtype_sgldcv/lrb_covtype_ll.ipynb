{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules and set up environment \n",
    "import os\n",
    "import sys\n",
    "path = \"../../src/\"\n",
    "\n",
    "sys.path.append(path)\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap, hessian, scipy, random\n",
    "\n",
    "#import sgmcmc code \n",
    "import models.logistic_regression.logistic_regression as lr\n",
    "import samplers.sgd as sgd\n",
    "import samplers.sgld as sgldcv\n",
    "import samplers.sgldps as sgldcvps\n",
    "\n",
    "from metrics import logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data\n",
    "file_path = \"../../data/real/covtype_train.csv\"\n",
    "test_path = \"../../data/real/covtype_test.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "dat_array = data.values[:]\n",
    "N = dat_array.shape[0]\n",
    "x = np.column_stack([np.ones(N), dat_array[:, 1:]])\n",
    "y = dat_array[:,0]\n",
    "test_data = pd.read_csv(test_path)\n",
    "test_array = test_data.values[:]\n",
    "N_test = test_array.shape[0]\n",
    "x_test = np.column_stack([np.ones(N_test), test_array[:, 1:]])\n",
    "y_test = test_array[:,0]\n",
    "\n",
    "#set up model parameters\n",
    "dim = x.shape[1] \n",
    "\n",
    "#priors\n",
    "mu_0 = np.zeros(dim) #prior mean\n",
    "lambda_0 = 10.0*np.eye(dim)  #prior covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"sgld\", \"sgldps\", \"sgldcv\", \"sgldcvps\"]\n",
    "sgld_batches = 0.01\n",
    "samples_csv = dict()\n",
    "Niter_sgld = 10**4\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    method = methods[i]\n",
    "    items = glob.glob(f\"./out/lrb_{method}_samples.csv\")[0]\n",
    "    samples_csv[method] = pd.read_csv(items).iloc[(Niter_sgld+1):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods: 100%|██████████| 4/4 [11:37<00:00, 174.35s/it]\n"
     ]
    }
   ],
   "source": [
    "Nrep = 10\n",
    "y_test = y_test.reshape((N_test, 1))\n",
    "\n",
    "for k in tqdm(range(len(methods)), desc= \"Methods\"):\n",
    "    method = methods[k]\n",
    "    idx=np.arange(Niter_sgld, 0, -10)[::-1]-1\n",
    "    ll_arr = np.zeros((idx.shape[0], Nrep))\n",
    "    for j in range(Nrep):\n",
    "        for i in range(idx.shape[0]):\n",
    "            index = idx[i]\n",
    "            sample = samples_csv[method].values[index, (dim*(j+1)):dim*(j+2)]\n",
    "            ll_arr[i,j] = logloss(sample, x_test, y_test)\n",
    "            \n",
    "        \n",
    "    ll_arr_df = pd.DataFrame(ll_arr)\n",
    "    ll_arr_df.to_csv(f\"./out/llcover_{method}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
