{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules and set up environment \n",
    "import os\n",
    "import sys\n",
    "path = \"../../src/\"\n",
    "\n",
    "sys.path.append(path)\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap, hessian, scipy, random\n",
    "\n",
    "#import sgmcmc code \n",
    "import models.logistic_regression.logistic_regression as lr\n",
    "import samplers.sgd as sgd\n",
    "import samplers.sgld as sgld\n",
    "import samplers.sgldps as sgldps\n",
    "\n",
    "from metrics import imq_KSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data\n",
    "file_path = \"../../data/real/covtype_train.csv\"\n",
    "test_path = \"../../data/real/covtype_test.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "dat_array = data.values[:]\n",
    "N = dat_array.shape[0]\n",
    "x = np.column_stack([np.ones(N), dat_array[:, 1:]])\n",
    "y = dat_array[:,0]\n",
    "test_data = pd.read_csv(test_path)\n",
    "test_array = test_data.values[:]\n",
    "N_test = test_array.shape[0]\n",
    "x_test = np.column_stack([np.ones(N_test), test_array[:, 1:]])\n",
    "y_test = test_array[:,0]\n",
    "\n",
    "#set up model parameters\n",
    "dim = x.shape[1] \n",
    "\n",
    "#priors\n",
    "mu_0 = np.zeros(dim) #prior mean\n",
    "lambda_0 = 10.0*np.eye(dim)  #prior covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"sgld_1\", \"sgldps_1\", \"sgld_5\", \"sgldps_5\",\"sgld_10\", \"sgldps_10\"]\n",
    "sgld_batches =[0.01, 0.01, 0.05, 0.05, 0.1, 0.1]\n",
    "samples_csv = dict()\n",
    "for i in range(len(methods)):\n",
    "    method = methods[i]\n",
    "    items = glob.glob(f\"./out/lrb_{method}_samples.csv\")[0]\n",
    "    idx = (np.int64(500/sgld_batches[i])+1)\n",
    "    samples_csv[method] = pd.read_csv(items).iloc[idx:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_csv = dict()\n",
    "sgld_methods = [\"sgld_1\", \"sgld_5\", \"sgld_10\"]\n",
    "grad_batches =[0.01, 0.05, 0.1]\n",
    "for i in range(len(sgld_methods)):\n",
    "    method = sgld_methods[i]\n",
    "    items = glob.glob(f\"./out/lrb_{method}_grads.csv\")[0]\n",
    "    grads_csv[method] = pd.read_csv(items).iloc[(np.int64(500/grad_batches[i])+1):].reset_index(drop=True)\n",
    "\n",
    "sgldps_methods = [\"sgldps_1\", \"sgldps_5\", \"sgldps_10\"]\n",
    "for i in range(len(sgldps_methods)):\n",
    "    method = sgldps_methods[i]\n",
    "    items = glob.glob(f\"./out/lrb_{method}_grads.csv\")[0]\n",
    "    grads_csv[method] = pd.read_csv(items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KSD evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nrep = 10\n",
    "ksd= dict()\n",
    "methods = [\"sgld_1\", \"sgldps_1\", \"sgld_5\", \"sgldps_5\",\"sgld_10\", \"sgldps_10\"]\n",
    "sgld_batches =[0.01, 0.01, 0.05, 0.05, 0.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Methods:   0%|          | 0/6 [00:00<?, ?it/s]WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Methods: 100%|██████████| 6/6 [56:08:18<00:00, 33683.08s/it]    \n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(len(methods)), desc= \"Methods\"):\n",
    "    method = methods[k]\n",
    "    idx=np.arange(np.int64(500/sgld_batches[k]), 0, -np.int64(10/sgld_batches[k]))[::-1]-1\n",
    "    ksd_arr = np.zeros((idx.shape[0], Nrep))\n",
    "    for j in range(Nrep):\n",
    "        for i in range(idx.shape[0]):\n",
    "            index = idx[i]\n",
    "            samples = samples_csv[method].values[:index, (dim*(j+1)):dim*(j+2)]\n",
    "            grads = grads_csv[method].values[:index, (dim*(j+1)):dim*(j+2)]\n",
    "            ksd_arr[i, j] = np.log10(imq_KSD(samples, grads))\n",
    "        \n",
    "    ksd_arr_df = pd.DataFrame(ksd_arr)\n",
    "    ksd[method] = ksd_arr_df\n",
    "    ksd_arr_df.to_csv(f\"./out/ksdcover_{method}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
