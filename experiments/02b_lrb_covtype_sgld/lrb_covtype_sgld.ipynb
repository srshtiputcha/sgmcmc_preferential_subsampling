{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "#import modules and set up environment \n",
    "import os\n",
    "import sys\n",
    "path = \"../../src/\"\n",
    "\n",
    "sys.path.append(path)\n",
    "\n",
    "sys.path.append(path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap, hessian, scipy, random\n",
    "\n",
    "#import sgmcmc code \n",
    "import models.logistic_regression.logistic_regression as lr\n",
    "import samplers.sgld as sgld\n",
    "import samplers.sgldps as sgldps\n",
    "import samplers.sgd as sgd\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up model-specific gradient functions\n",
    "gradf_0 = lr.gradf_0\n",
    "gradf_i_batch = lr.gradf_i_batch\n",
    "post_var = lr.post_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data\n",
    "file_path = \"../../data/real/covtype_train.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "dat_array = data.values[:]\n",
    "N = dat_array.shape[0]\n",
    "x = np.column_stack([np.ones(N), dat_array[:, 1:]])\n",
    "y = dat_array[:,0]\n",
    "\n",
    "#set up model parameters\n",
    "dim = x.shape[1] \n",
    "\n",
    "#priors\n",
    "mu_0 = np.zeros(dim) #prior mean\n",
    "lambda_0 = 10.0*np.eye(dim)  #prior covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#results from a fast MLE\n",
    "#lr = LogisticRegression()\n",
    "#lr.fit(dat_array[:, 1:], y)\n",
    "#mle = np.concatenate((lr.intercept_,lr.coef_[0,:]))\n",
    "\n",
    "#print(\"MLE estimates: \", \"\\n\", mle, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sampling framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-size\n",
    "step_size = 10**(-6)\n",
    "# batch sizes\n",
    "n_batch = np.int64(N*np.array([0.01, 0.05, 0.1]))\n",
    "# number of chains\n",
    "N_rep = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD (0.01N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_batch[0]\n",
    "burnin = np.int64(500/0.01)\n",
    "Niter = 2*burnin\n",
    "\n",
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [1:29:21<00:00, 487.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    samples, grads, runtime = sgld.sgld_sampler(subkey, gradf_0, gradf_i_batch, Niter, step_size, theta_0, x, y, n, replacement=True)\n",
    "    runtime_df.append(runtime)\n",
    "    samples_df.append(samples)\n",
    "    grads_df.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_sgld_1_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_sgld_1_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_sgld_1_grads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD (0.05N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_batch[1]\n",
    "burnin = np.int64(500/0.05)\n",
    "Niter = 2*burnin\n",
    "\n",
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [32:16<00:00, 176.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    samples, grads, runtime = sgld.sgld_sampler(subkey, gradf_0, gradf_i_batch, Niter, step_size, theta_0, x, y, n, replacement=True)\n",
    "    runtime_df.append(runtime)\n",
    "    samples_df.append(samples)\n",
    "    grads_df.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_sgld_5_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_sgld_5_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_sgld_5_grads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD (0.1N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_batch[2]\n",
    "burnin = np.int64(500/0.1)\n",
    "Niter = 2*burnin\n",
    "\n",
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [27:48<00:00, 151.66s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    samples, grads, runtime = sgld.sgld_sampler(subkey, gradf_0, gradf_i_batch, Niter, step_size, theta_0, x, y, n, replacement=True)\n",
    "    runtime_df.append(runtime)\n",
    "    samples_df.append(samples)\n",
    "    grads_df.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_sgld_10_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_sgld_10_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_sgld_10_grads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD-PS (0.01N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_batch[0]\n",
    "burnin = np.int64(500/0.01)\n",
    "step_sgd = 1e-03\n",
    "Niter = 2*burnin\n",
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [3:01:24<00:00, 989.53s/it]  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    theta_hat, samples_sgd, runtime_sgd = sgd.adam(key, gradf_0, gradf_i_batch, burnin, theta_0, x, y, n, step_sgd, replacement=True)\n",
    "    samples, grads, runtime = sgldps.sgldps_sampler(subkey, gradf_0, gradf_i_batch, burnin, step_size, theta_hat, theta_hat, x, y, n,  prob_type='approx')\n",
    "        \n",
    "    runtime_df.append(np.concatenate((runtime_sgd, runtime_sgd[burnin-1]+runtime)))\n",
    "    samples_df.append(np.concatenate((samples_sgd, samples[1:]), axis=0))\n",
    "    grads_df.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_sgldps_1_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_sgldps_1_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_sgldps_1_grads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD-PS (0.05N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_batch[1]\n",
    "burnin = np.int64(500/0.05)\n",
    "Niter = 2*burnin\n",
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [1:44:17<00:00, 568.91s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    theta_hat, samples_sgd, runtime_sgd = sgd.adam(key, gradf_0, gradf_i_batch, burnin, theta_0, x, y, n, step_sgd, replacement=True)\n",
    "    samples, grads, runtime = sgldps.sgldps_sampler(subkey, gradf_0, gradf_i_batch, burnin, step_size, theta_hat, theta_hat, x, y, n,  prob_type='approx')\n",
    "        \n",
    "    runtime_df.append(np.concatenate((runtime_sgd, runtime_sgd[burnin-1]+runtime)))\n",
    "    samples_df.append(np.concatenate((samples_sgd, samples[1:]), axis=0))\n",
    "    grads_df.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_sgldps_5_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_sgldps_5_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_sgldps_5_grads.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD-PS (0.1N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_batch[2]\n",
    "burnin = np.int64(500/0.1)\n",
    "Niter = 2*burnin\n",
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [1:35:35<00:00, 521.42s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    theta_hat, samples_sgd, runtime_sgd = sgd.adam(key, gradf_0, gradf_i_batch, burnin, theta_0, x, y, n, step_sgd, replacement=True)\n",
    "    samples, grads, runtime = sgldps.sgldps_sampler(subkey, gradf_0, gradf_i_batch, burnin, step_size, theta_hat, theta_hat, x, y, n,  prob_type='approx')\n",
    "        \n",
    "    runtime_df.append(np.concatenate((runtime_sgd, runtime_sgd[burnin-1]+runtime)))\n",
    "    samples_df.append(np.concatenate((samples_sgd, samples[1:]), axis=0))\n",
    "    grads_df.append(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_sgldps_10_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_sgldps_10_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_sgldps_10_grads.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
