{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "#import modules and set up environment \n",
    "import os\n",
    "import sys\n",
    "path = \"../../src/\"\n",
    "\n",
    "sys.path.append(path)\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap, hessian, scipy, random\n",
    "\n",
    "#import sgmcmc code \n",
    "\n",
    "import models.logistic_regression.logistic_regression as lr\n",
    "from samplers import sgd as sgd\n",
    "from samplers import sgld as sgld\n",
    "from samplers import sgldps as sgldps\n",
    "from samplers import sgldcv as sgldcv\n",
    "from samplers import sgldcvps as sgldcvps\n",
    "\n",
    "key = random.PRNGKey(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up model-specific gradient functions\n",
    "gradf_0 = lr.gradf_0\n",
    "gradf_i_batch = lr.gradf_i_batch\n",
    "post_var = lr.post_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data\n",
    "file_path = \"../../data/synthetic/lr_balance_train_synth.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "dat_array = data.values[:]\n",
    "N = dat_array.shape[0]\n",
    "x = dat_array[:, 1:]\n",
    "y = dat_array[:,0]\n",
    "\n",
    "#set up model parameters\n",
    "dim = x.shape[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sampling framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-size\n",
    "step_size = 1e-4\n",
    "step_sgd = 1e-3\n",
    "# batch sizes\n",
    "n_batch = np.int64(N*0.001)\n",
    "# number of chains (first chain discarded due to slower runtime)\n",
    "N_rep = 11\n",
    "#iterations\n",
    "burnin = np.int64(10/0.001)\n",
    "Niter = 2*burnin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating V_0 for ASGLD-CV sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_samples = pd.read_csv(\"./out/lrb_sgldcv_samples.csv\").iloc[burnin:].reset_index(drop=True)\n",
    "modes_cv = cv_samples.values[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_cv = np.zeros(N_rep-1)\n",
    "for i in range(1, N_rep):\n",
    "    mode = modes_cv[(i-1)*(dim):i*dim]\n",
    "    dists = np.sum((cv_samples.values[:, (i-1)*(dim):i*dim] - mode)**2, axis=1)\n",
    "    quantiles_cv[i-1] = np.quantile(dists, q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04352772, 0.04238889, 0.05069752, 0.04276705, 0.04196886,\n",
       "       0.03771035, 0.03906198, 0.04459311, 0.04425378, 0.04224128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipschitz_cv = np.zeros(N)\n",
    "for i in range(N):\n",
    "    xxT = np.outer(x[i,:], x[i, :].T) + 1e-10*np.eye(dim)\n",
    "    lipschitz_cv[i] = np.max(np.linalg.eigh(xxT)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_0_cv = (1/n_batch)*quantiles_cv*N*np.sum(lipschitz_cv**2)\n",
    "max_V_0_cv = np.max(V_0_cv)\n",
    "cons_cv = 1/max_V_0_cv * N*np.sum(lipschitz_cv**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.24832543695533"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating V_0 for ASGLD-CV sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvps_samples = pd.read_csv(\"./out/lrb_sgldcvps_samples.csv\").iloc[burnin:].reset_index(drop=True)\n",
    "modes_cvps = cvps_samples.values[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_cvps = np.zeros(N_rep-1)\n",
    "for i in range(1, N_rep):\n",
    "    mode = modes_cvps[(i-1)*(dim):i*dim]\n",
    "    dists = np.sum((cvps_samples.values[:, (i-1)*(dim):i*dim] - mode)**2, axis=1)\n",
    "    quantiles_cvps[i-1] = np.quantile(dists, q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04591819, 0.04678468, 0.04261566, 0.0439665 , 0.04541675,\n",
       "       0.04435076, 0.04942472, 0.04619804, 0.04464653, 0.04376622])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles_cvps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipschitz_cvps = np.zeros(N)\n",
    "for i in range(N):\n",
    "    xxT = np.outer(x[i,:], x[i, :].T) + 1e-10*np.eye(dim)\n",
    "    lipschitz_cvps[i] = 0.25 * np.max(np.linalg.eigh(xxT)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_0_cvps = (1/n_batch)*quantiles_cvps*N*np.sum(lipschitz_cvps**2)\n",
    "max_V_0_cvps = np.max(V_0_cvps)\n",
    "cons_cvps = 1/max_V_0_cvps * N*np.sum(lipschitz_cvps**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.3279062402471"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_cvps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the adaptive SGLD-CV sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []\n",
    "n_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [09:58<00:00, 54.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    theta_hat, samples_sgd, runtime_sgd = sgd.adam(key, gradf_0, gradf_i_batch, burnin, theta_0, x, y, n_batch, step_sgd, replacement=True)\n",
    "    samples, grads, runtime, n_vec = sgldcv.asgld_cv_sampler(subkey, gradf_0, gradf_i_batch, burnin, step_size, theta_hat, \n",
    "                                                             theta_hat, x, y, cons_cv, replacement=True)    \n",
    "    runtime_df.append(np.concatenate((runtime_sgd, runtime_sgd[burnin-1]+runtime))) #join output\n",
    "    samples_df.append(np.concatenate((samples_sgd, samples[1:]), axis=0))\n",
    "    grads_df.append(grads)\n",
    "    n_df.append(n_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df)) #save output\n",
    "runtime_df.to_csv(\"./out/lrb_asgldcv_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_asgldcv_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_asgldcv_grads.csv\", index=False)\n",
    "n_df = pd.DataFrame(np.column_stack(n_df))\n",
    "n_df.to_csv(\"./out/lrb_asgldcv_n.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the ASGLD-CV-PS sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df=[]\n",
    "samples_df = []\n",
    "grads_df = []\n",
    "n_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of chains run: 100%|██████████| 11/11 [14:47<00:00, 80.70s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(N_rep), desc = \"Number of chains run\"):\n",
    "    key, subkey = random.split(key)\n",
    "    theta_0 = jnp.zeros(dim)\n",
    "    theta_hat, samples_sgd, runtime_sgd = sgd.adam(key, gradf_0, gradf_i_batch, burnin, theta_0, x, y, \n",
    "                                                   n_batch, step_sgd, replacement=True)\n",
    "    samples, grads, runtime, n_vec, probs = sgldcvps.asgld_cv_ps_sampler(subkey, gradf_0, gradf_i_batch, post_var, burnin, \n",
    "                                                                         step_size, theta_hat, theta_hat, x, y, cons_cvps)\n",
    "    runtime_df.append(np.concatenate((runtime_sgd, runtime_sgd[burnin-1]+runtime))) #join output\n",
    "    samples_df.append(np.concatenate((samples_sgd, samples[1:]), axis=0))\n",
    "    grads_df.append(grads) \n",
    "    n_df.append(n_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df = pd.DataFrame(np.column_stack(runtime_df))\n",
    "runtime_df.to_csv(\"./out/lrb_asgldcvps_runtime.csv\", index=False)\n",
    "samples_df = pd.DataFrame(np.column_stack(samples_df))\n",
    "samples_df.to_csv(\"./out/lrb_asgldcvps_samples.csv\", index=False)\n",
    "grads_df = pd.DataFrame(np.column_stack(grads_df))\n",
    "grads_df.to_csv(\"./out/lrb_asgldcvps_grads.csv\", index=False)\n",
    "n_df = pd.DataFrame(np.column_stack(n_df))\n",
    "n_df.to_csv(\"./out/lrb_asgldcvps_n.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
